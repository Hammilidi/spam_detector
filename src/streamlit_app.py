import streamlit as st
import pickle
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import nltk
import string
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
import numpy as np

# Configuration de la page
st.set_page_config(
    page_title="BMSecurity - D√©tecteur de Spam",
    page_icon="üõ°Ô∏è",
    layout="wide"
)

# Fonction de pr√©traitement (identique √† celle du notebook)
@st.cache_data
def preprocess_text(text):
    """Fonction de pr√©traitement du texte"""
    if pd.isna(text) or not text.strip():
        return ""

    stemmer = PorterStemmer()
    stop_words = set(stopwords.words('english'))

    # Conversion en minuscules
    text = text.lower()

    # Suppression de la ponctuation et des caract√®res sp√©ciaux
    text = re.sub(r'[^a-zA-Z\s]', '', text)

    # Tokenisation
    tokens = word_tokenize(text)

    # Suppression des stopwords et stemming
    processed_tokens = []
    for token in tokens:
        if token not in stop_words and len(token) > 2:
            processed_tokens.append(stemmer.stem(token))

    return ' '.join(processed_tokens)

# Chargement du mod√®le et du vectoriseur
@st.cache_resource
def load_models():
    """Chargement des mod√®les sauvegard√©s"""
    try:
        with open('../models/spam_detection_model.pkl', 'rb') as f:
            model = pickle.load(f)
        with open('../models/tfidf_vectorizer.pkl', 'rb') as f:
            vectorizer = pickle.load(f)
        return model, vectorizer
    except Exception as e:
        st.error(f"Erreur lors du chargement des mod√®les: {e}")
        return None, None

# Fonction de pr√©diction
def predict_email(text, model, vectorizer):
    """Pr√©diction pour un email donn√©"""
    try:
        # Pr√©traitement
        processed_text = preprocess_text(text)

        if not processed_text.strip():
            return {
                'prediction': 'ham',
                'probability': 0.5,
                'confidence': 'Low',
                'error': 'Texte vide apr√®s pr√©traitement'
            }

        # Vectorisation
        text_vectorized = vectorizer.transform([processed_text])

        # Pr√©diction
        prediction = model.predict(text_vectorized)[0]
        probabilities = model.predict_proba(text_vectorized)[0]

        # Interpr√©tation
        label = 'spam' if prediction == 1 else 'ham'
        confidence_score = max(probabilities)

        if confidence_score > 0.8:
            confidence = 'High'
        elif confidence_score > 0.6:
            confidence = 'Medium'
        else:
            confidence = 'Low'

        return {
            'prediction': label,
            'probability': confidence_score,
            'confidence': confidence,
            'probabilities': {
                'ham': probabilities[0],
                'spam': probabilities[1]
            }
        }

    except Exception as e:
        return {
            'prediction': 'ham',
            'probability': 0.5,
            'confidence': 'Low',
            'error': str(e)
        }

def main():
    st.title("üõ°Ô∏è BMSecurity - Syst√®me de D√©tection de Spam")
    st.markdown("*Solution intelligente pour la s√©curit√© des communications*")
    st.markdown("---")

    # Chargement des mod√®les
    model, vectorizer = load_models()

    if model is None or vectorizer is None:
        st.error("Impossible de charger les mod√®les. Veuillez v√©rifier les fichiers.")
        return

    # Sidebar pour la navigation
    st.sidebar.title("üöÄ Navigation")
    page = st.sidebar.selectbox(
        "Choisir une section",
        ["üè† Accueil", "üìß D√©tection", "üìä Statistiques", "üîç Analyse", "‚ÑπÔ∏è √Ä propos"]
    )

    if page == "üè† Accueil":
        st.header("üè† Bienvenue dans le syst√®me de d√©tection de spam")

        st.write("""
        ### üéØ Objectif
        Cette application utilise des techniques avanc√©es de **Machine Learning** et de 
        **Traitement du Langage Naturel (NLP)** pour d√©tecter automatiquement les emails 
        malveillants et prot√©ger vos communications.
        """)

        # M√©triques de performance bas√©es sur les graphiques fournis
        st.subheader("üìà Performances des Mod√®les")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("üéØ Accuracy (SVM)", "98.7%", "‚ÜóÔ∏è Meilleur")
        with col2:
            st.metric("üîç Precision (SVM)", "98.2%", "‚ÜóÔ∏è Excellent")
        with col3:
            st.metric("üì° Recall (SVM)", "99.4%", "‚ÜóÔ∏è Optimal")
        with col4:
            st.metric("‚öñÔ∏è F1-Score (SVM)", "98.8%", "‚ÜóÔ∏è Top")

        # Fonctionnalit√©s
        st.subheader("üõ†Ô∏è Fonctionnalit√©s")

        col1, col2 = st.columns(2)

        with col1:
            st.write("""
            **üîß Pr√©traitement Avanc√©:**
            - Tokenisation intelligente
            - Suppression des mots vides
            - Stemming et normalisation
            - Vectorisation TF-IDF
            """)

        with col2:
            st.write("""
            **ü§ñ Algorithmes Utilis√©s:**
            - Support Vector Machine (SVM) - **Recommand√©**
            - Naive Bayes Multinomial
            - Decision Trees optimis√©s
            - Validation crois√©e 5-fold
            """)

        # Instructions
        st.subheader("üöÄ Comment utiliser l'application")
        st.write("""
        1. **üìß D√©tection** : Analysez un email en temps r√©el
        2. **üìä Statistiques** : Consultez les performances d√©taill√©es des 3 mod√®les
        3. **üîç Analyse** : Explorez les patterns dans les donn√©es (wordclouds, distributions)
        4. **‚ÑπÔ∏è √Ä propos** : D√©couvrez les d√©tails techniques
        """)

    elif page == "üìß D√©tection":
        st.header("üìß Analyser un Email")
        st.write("Collez le contenu de votre email ci-dessous pour une analyse instantan√©e.")

        # Zone de saisie
        email_text = st.text_area(
            "üìù Contenu de l'email :",
            placeholder="Collez ici le texte de l'email √† analyser...",
            height=200
        )

        # Exemples d'emails
        st.subheader("üí° Exemples d'emails √† tester")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("üìß Email L√©gitime", type="secondary"):
                st.session_state.email_example = "Hello team, I wanted to remind you about our meeting tomorrow at 3 PM in conference room A. Please bring your quarterly reports and be prepared to discuss the upcoming project milestones. Looking forward to seeing everyone there. Best regards, John"

        with col2:
            if st.button("üö® Email Suspect", type="secondary"):
                st.session_state.email_example = "URGENT! CONGRATULATIONS! You have won $1,000,000 in our international lottery! Send your bank details immediately to claim your prize. Act now before this offer expires! Click here to claim your money now!"

        # Afficher l'exemple s√©lectionn√©
        if 'email_example' in st.session_state:
            email_text = st.text_area(
                "üìù Contenu de l'email (exemple s√©lectionn√©) :",
                value=st.session_state.email_example,
                height=200,
                key="email_content"
            )

        # Bouton d'analyse
        if st.button("üîç Analyser l'Email", type="primary"):
            if email_text.strip():
                with st.spinner("üîÑ Analyse en cours..."):
                    result = predict_email(email_text, model, vectorizer)

                # Affichage des r√©sultats
                st.markdown("---")
                st.subheader("üìã R√©sultats de l'Analyse")

                # R√©sultat principal
                if result['prediction'] == 'spam':
                    st.error(f"üö® **SPAM D√âTECT√â**")
                    st.markdown(f"**Niveau de confiance :** {result['confidence']} ({result['probability']:.1%})")
                else:
                    st.success(f"‚úÖ **EMAIL L√âGITIME**")
                    st.markdown(f"**Niveau de confiance :** {result['confidence']} ({result['probability']:.1%})")

                # D√©tails des probabilit√©s
                st.subheader("üìä Probabilit√©s D√©taill√©es")

                # Graphique en barres
                fig, ax = plt.subplots(figsize=(8, 4))
                categories = ['Email L√©gitime', 'Spam']
                probabilities = [result['probabilities']['ham'], result['probabilities']['spam']]
                colors = ['green' if result['prediction'] == 'ham' else 'lightgreen',
                         'red' if result['prediction'] == 'spam' else 'lightcoral']

                bars = ax.bar(categories, probabilities, color=colors, alpha=0.7)
                ax.set_ylabel('Probabilit√©')
                ax.set_title('Distribution des Probabilit√©s')
                ax.set_ylim(0, 1)

                # Ajout des valeurs sur les barres
                for bar, prob in zip(bars, probabilities):
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                           f'{prob:.1%}', ha='center', va='bottom', fontweight='bold')

                st.pyplot(fig)
                plt.close()

                # Gauge de confiance
                st.subheader("üéØ Niveau de Confiance")
                confidence_value = result['probability']

                # Cr√©ation d'une gauge simple
                fig, ax = plt.subplots(figsize=(8, 3))

                # Barre de progression
                ax.barh(0, confidence_value, color='green' if confidence_value > 0.7 else 'orange' if confidence_value > 0.5 else 'red', alpha=0.7)
                ax.set_xlim(0, 1)
                ax.set_ylim(-0.5, 0.5)
                ax.set_xlabel('Niveau de Confiance')
                ax.set_title(f'Confiance: {confidence_value:.1%} ({result["confidence"]})')
                ax.set_yticks([])

                # Marqueurs de seuils
                ax.axvline(x=0.5, color='orange', linestyle='--', alpha=0.5, label='Seuil Moyen')
                ax.axvline(x=0.7, color='green', linestyle='--', alpha=0.5, label='Seuil √âlev√©')
                ax.legend()

                st.pyplot(fig)
                plt.close()

                # Recommandations
                st.subheader("üí° Recommandations")

                if result['confidence'] == 'High':
                    if result['prediction'] == 'spam':
                        st.warning("""
                        ‚ö†Ô∏è **Action Recommand√©e :** 
                        - Supprimez cet email imm√©diatement
                        - Ne cliquez sur aucun lien
                        - Signalez-le comme spam
                        """)
                    else:
                        st.info("""
                        ‚úÖ **Email Fiable :** 
                        - Cet email semble l√©gitime
                        - Vous pouvez le traiter normalement
                        """)
                else:
                    st.warning("""
                    ü§î **V√©rification Manuelle Recommand√©e :** 
                    - Le mod√®le n'est pas certain
                    - Examinez l'email plus attentivement
                    - V√©rifiez l'exp√©diteur et le contenu
                    """)

            else:
                st.warning("‚ö†Ô∏è Veuillez saisir un email √† analyser.")

    elif page == "üìä Statistiques":
        st.header("üìä Performances et Statistiques des Mod√®les")

        # Interpr√©tation des r√©sultats bas√©e sur les graphiques
        st.subheader("üéØ Analyse Comparative des Mod√®les")
        
        st.write("""
        Bas√© sur l'analyse des performances des trois mod√®les test√©s, voici les r√©sultats d√©taill√©s :
        """)

        # M√©triques d√©taill√©es avec interpr√©tation
        st.subheader("üìà R√©sultats de Performance")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("### üå≥ Decision Tree")
            st.metric("Accuracy", "95.6%")
            st.metric("Precision", "96.1%") 
            st.metric("Recall", "95.9%")
            st.metric("F1-Score", "96.0%")

        with col2:
            st.markdown("### üìä Naive Bayes")
            st.metric("Accuracy", "98.1%")
            st.metric("Precision", "97.7%")
            st.metric("Recall", "98.7%") 
            st.metric("F1-Score", "98.2%")

        with col3:
            st.markdown("### üéØ SVM (Recommand√©)")
            st.metric("Accuracy", "98.7%", "üèÜ")
            st.metric("Precision", "98.2%", "üèÜ")
            st.metric("Recall", "99.4%", "üèÜ") 
            st.metric("F1-Score", "98.8%", "üèÜ")

        # Graphique de comparaison des performances
        st.subheader("üìä Comparaison Visuelle des Performances")
        try:
            st.image("plots/comparaison_performances_models.png", 
                    caption="Comparaison des m√©triques de performance entre les trois mod√®les", 
                    use_container_width=True)
        except:
            st.info("Graphique de comparaison non disponible. Veuillez v√©rifier le fichier.")

        # Validation crois√©e
        st.subheader("üîÑ Validation Crois√©e")
        st.write("""
        **Analyse de la stabilit√© des mod√®les :**
        - **Decision Tree** : 95.6% ¬± 0.002 (Stable mais performance plus faible)
        - **Naive Bayes** : 98.1% ¬± 0.001 (Tr√®s stable et performant)
        - **SVM** : 98.7% ¬± 0.001 (Le plus stable ET le plus performant)
        """)

        try:
            st.image("plots/confusion_models.png", 
                    caption="Matrices de confusion pour les trois mod√®les", 
                    use_container_width=True)
        except:
            st.info("Matrices de confusion non disponibles. Veuillez v√©rifier le fichier.")

        # Interpr√©tation des matrices de confusion
        st.subheader("üîç Analyse des Matrices de Confusion")
        
        st.write("""
        **Observations cl√©s :**
        
        1. **SVM** montre les meilleures performances avec :
           - Tr√®s peu de faux positifs (80 emails l√©gitimes class√©s comme spam)
           - Tr√®s peu de faux n√©gatifs (21 spams non d√©tect√©s)
           - Meilleur √©quilibre global
        
        2. **Naive Bayes** :
           - Performance solide avec 76 faux positifs et 43 faux n√©gatifs
           - Bon compromis entre pr√©cision et rappel
        
        3. **Decision Tree** :
           - Plus de faux positifs (125) et faux n√©gatifs (134)
           - Performance inf√©rieure mais toujours acceptable
        """)

        # Recommandation
        st.success("""
        **üèÜ Recommandation :** Le mod√®le **SVM** est recommand√© pour la production gr√¢ce √† :
        - Sa pr√©cision exceptionnelle (98.7%)
        - Son excellent rappel (99.4% - d√©tecte presque tous les spams)
        - Sa stabilit√© en validation crois√©e
        """)

    elif page == "üîç Analyse":
        st.header("üîç Analyse Exploratoire et Visualisations")

        # Nuages de mots
        st.subheader("‚òÅÔ∏è Analyse des Mots Fr√©quents")
        
        st.write("""
        Les nuages de mots r√©v√®lent les patterns linguistiques distinctifs entre 
        les emails l√©gitimes et les spams :
        """)

        try:
            st.image("plots/word_cloud.png", 
                    caption="Comparaison des mots fr√©quents : SPAM vs Emails L√©gitimes", 
                    use_container_width=True)
        except:
            st.info("Nuages de mots non disponibles. Veuillez v√©rifier le fichier.")

        # Interpr√©tation des word clouds
        st.subheader("üìù Interpr√©tation des Patterns Linguistiques")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üö® Mots Typiques des SPAMS")
            st.write("""
            - **"money", "make", "win"** : Promesses financi√®res
            - **"free", "offer", "company"** : Offres trop belles
            - **"want", "need", "one"** : Langage urgent/pressant
            - **"email", "business"** : Contexte commercial agressif
            """)
            
        with col2:
            st.markdown("#### ‚úÖ Mots Typiques des Emails L√©gitimes")
            st.write("""
            - **"enron", "energy", "gas"** : Contexte professionnel sp√©cifique
            - **"meet", "time", "work"** : Communication d'entreprise
            - **"thank", "question", "help"** : Ton poli et collaboratif
            - **"project", "business"** : Discussions professionnelles
            """)

        # Distribution des longueurs
        st.subheader("üìè Analyse des Caract√©ristiques Textuelles")
        
        try:
            st.image("plots/distribution.png", 
                    caption="Distribution des longueurs de texte et nombre de mots par classe", 
                    use_container_width=True)
        except:
            st.info("Graphiques de distribution non disponibles. Veuillez v√©rifier le fichier.")

        # Interpr√©tation des distributions
        st.subheader("üìä Insights sur les Caract√©ristiques Textuelles")
        
        st.write("""
        **Observations importantes :**
        
        1. **Longueur des textes :**
           - Les emails **l√©gitimes** sont g√©n√©ralement plus longs (~1650 caract√®res en moyenne)
           - Les **spams** sont plus courts (~1350 caract√®res) mais plus variables
        
        2. **Nombre de mots :**
           - Les emails **l√©gitimes** contiennent plus de mots (~350 mots)
           - Les **spams** sont plus concis (~260 mots) pour un impact rapide
        
        3. **Implications pour la d√©tection :**
           - La longueur peut √™tre un indicateur utile
           - Les spams privil√©gient la concision et l'impact
           - Les emails l√©gitimes tendent vers plus de d√©tails
        """)

        # Features importantes
        st.subheader("üîç Features les Plus Discriminantes")
        
        st.write("""
        **Caract√©ristiques cl√©s identifi√©es par les mod√®les :**
        
        - **Vocabulaire financier** : "money", "win", "prize", "cash"
        - **Urgence artificielle** : "urgent", "act now", "limited time"
        - **Formulations suspectes** : "click here", "free", "guarantee"
        - **Ton professionnel vs commercial** : Diff√©rence marqu√©e dans le registre de langue
        """)

    elif page == "‚ÑπÔ∏è √Ä propos":
        st.header("‚ÑπÔ∏è √Ä Propos du Projet")

        st.markdown("""
        ## üéØ Contexte du Projet

        Ce syst√®me de d√©tection de spam a √©t√© d√©velopp√© par **BMSecurity** dans le cadre 
        du renforcement de la s√©curit√© des communications. Il constitue la base d'une 
        solution √©volutive destin√©e √† √™tre int√©gr√©e aux plateformes de messagerie.

        ## üî¨ Approche Technique

        ### **Pr√©traitement du Texte**
        - Conversion en minuscules
        - Suppression de la ponctuation
        - Tokenisation avec NLTK
        - Suppression des mots vides (stopwords)
        - Stemming avec PorterStemmer

        ### **Extraction des Caract√©ristiques**
        - Vectorisation TF-IDF (Term Frequency-Inverse Document Frequency)
        - Matrice de 5000 caract√©ristiques maximum
        - Support des unigrammes et bigrammes

        ### **Mod√®les Test√©s et R√©sultats**
        - **Support Vector Machine (SVM)** : 98.7% accuracy - **Mod√®le s√©lectionn√©**
        - **Naive Bayes Multinomial** : 98.1% accuracy - Tr√®s bon second choix
        - **Decision Tree Classifier** : 95.6% accuracy - Performance acceptable

        ### **Validation et Optimisation**
        - Validation crois√©e 5-fold
        - Optimisation des hyperparam√®tres avec GridSearchCV
        - M√©triques : Accuracy, Precision, Recall, F1-Score

        ## üìä Architecture du Syst√®me

        ```
        Email Input ‚Üí Preprocessing ‚Üí TF-IDF ‚Üí SVM Model ‚Üí Classification
                         ‚Üì              ‚Üì         ‚Üì           ‚Üì
                    Tokenization   Vectorization  Prediction  Result
                    Stemming       Feature         Probability  Confidence
                    Cleaning       Extraction      Score       Level
        ```

        ## üõ†Ô∏è Technologies Utilis√©es

        - **Python 3.8+**
        - **Scikit-learn** : Algorithmes ML et preprocessing
        - **NLTK** : Traitement du langage naturel
        - **Pandas** : Manipulation des donn√©es
        - **Streamlit** : Interface web interactive
        - **Matplotlib/Seaborn** : Visualisations
        - **WordCloud** : Nuages de mots

        ## üìà Performances Finales (Mod√®le SVM)

        | M√©trique | Score | Interpr√©tation |
        |----------|-------|----------------|
        | Accuracy | 98.7% | Excellent taux de classification correcte |
        | Precision | 98.2% | Tr√®s peu de faux positifs |
        | Recall | 99.4% | D√©tecte presque tous les spams |
        | F1-Score | 98.8% | Excellent √©quilibre pr√©cision/rappel |

        ## üîç Insights Cl√©s du Projet

        1. **Le mod√®le SVM s'est r√©v√©l√© sup√©rieur** aux autres approches
        2. **Les spams utilisent un vocabulaire financier sp√©cifique** ("money", "win", "free")
        3. **Les emails l√©gitimes sont g√©n√©ralement plus longs** et d√©taill√©s
        4. **La validation crois√©e confirme la stabilit√©** des performances

        ## üöÄ Perspectives d'Am√©lioration

        - **Deep Learning** : Int√©gration de r√©seaux de neurones (LSTM, Transformers)
        - **Features Avanc√©es** : Analyse des m√©tadonn√©es, patterns temporels
        - **Apprentissage en Continu** : Mise √† jour automatique du mod√®le
        - **Multi-langues** : Support d'autres langues que l'anglais

        ## üë• √âquipe de D√©veloppement

        **BMSecurity - Intelligence Artificielle Team**

        *Ce projet a √©t√© r√©alis√© avec passion ‚ù§Ô∏è et expertise pour prot√©ger 
        vos communications contre les menaces num√©riques.*

        ---

        üìß **Contact :** yonlifidelis2@gmail.com  
        üåê **LinkedIn :** www.linkedin.com/in/yonlifidele 
        üìÖ **Version :** 1.0.0 (2025)
        """)

if __name__ == "__main__":
    main()